System	PlayType	1		ffffff
System	AnalysisDelay	2		Number of seconds between calls to analysis DLL with new image
System	LogFile	1		0- no logging, 1-log command, 2 log command and errors, 3 log command and all output(2,3 not working)
System	ShowBatchWindow	0		Set to 1 to show Batch window.  
System	Favorites	FFMPeg SourceMikeRecord$$Script VLC VLCShowImageFile$$Script VLC PLayDirectory$$Script FFPlay DisplayTwoFilesSideBySide$$Script FFMPeg RecordDesktop$$PlayList Files$$Script FFMPeg OverlayTitle$$		This is the list of favorites that user has selected.  This is maintained by Software and should not be updated.
System	ScriptTypes	FFPlay,FFMPeg,VLC,Photos,VideoFiles,AudioFiles,ImageFiles		Types for Scripts
System	FFMPegDefaultCmd	ffmpeg -i $FILE\VIDEOEXT$ 		Default commanf for new FFMPeg item
System	FFPlayDefaultCmd	ffplay "$FILE\VIDEOEX$" -loop 0		Default Command for new FFPlay item
System	VLCDefaultCmd	"C:\Program Files (x86)\VideoLAN\VLC\vlc.exe"  "$FILE\VIDEOEXT$"		Default command for new VLC type
System	PhotosDefaultCmd	start ms-photos:		Default command for Script type photos
System	VideoFilesDefaultCmd	$FILE\VIDEOEXT$		Default type for VideoFiles script type
System	AudioFilesDefaultCmd	$FILE\AUDIOEXT$		Default command for AudioFiles command type
System	FunctionsPlay	Play		Selected item for Functions select box.  Maintained by system
System	FunctionsScript	Play		Selected item for Script select box.  Maintained by system
System	UserStringDefType	TEXT		Default for user string type display.  Maintained by system.
System	MainWindowPosition	1415,0		Main Window position.  Maintained by system when window is moved.
System	AnalysisData	SampleTest/SampleDLL;SubTitler/SubTitle		List of User DLL's consisting of menuitem name and DLL name.  Dll must be available to program
System	Commands	ffplay,ffmpeg,vlc		Standard system commands
System	Prosigns	LOCALVIDEODEVICE\LOCALAUDIODEVICE\USERWINDOW\SIZE\DIRECTORY\MEDIADIRECTORY\MEDIAOUTDIRECTORY\FILE\FILEONLY\FILES\LANADDRESS\PROCESS\NEWFILE		System Prosigns
ffmpeg	codec	-vcodec:libx264,h261,h262,h263,h263i,h264,indeo2,indeo3,indeo4,indeo2-5,ljpeg,mjpeg,mjepb,mpeg1video,mpeg2,video,mpeg4,msmpeg4v1,msmpeg4v2,msmpeg4v3,msvideo1,mdec,libx264,codec2,dvaudio,mp1,mp2,mp3		
vlc	codec	-vcodec:H264,MPEG-2 Video - used in DVDs=mp2v,MPEG-4 Video=mp4v,Sorenson Video v1=SVQ1,Sorenson Video v3=SVQ3,VOB Video - used in DVDs=DVDv,Windows Media Video v1=WMV1,Windows Media Video v2=WMV2,Windows Media Video v3, also called Windows Media 9 ,Digital Video=DVSD,MJPEG=MJPG,H263=H263,H264=h264,Theora=theo,Indeo Video=IV20,Indeo Video version 4 or later=IV40,Real Media Video=RV10,Cinepak=cvid,On2 VP3=VP31,Flash Video=FLV1,Creative YUV=CYUV,Huffman YUV=HFYU,Microsoft Video v1=MSVC,Microsoft RLE Video=MRLE,Autodesk Animator Studio Codec RLE Video=AASC,FLIC video=FLIC,QPEG Video=QPEG,VP8 Video=VP8,MPEG audio ,MPEG Layer 3 audio=mp3,MP4 audio=mp4a,Dolby Digital ,Vorbis=vorb,Opus=opus,Speex=spx,FLAC=flac		
ffmpegother	Preset	-preset=1 		
ffmpegother	AudioCodec	-acodec=1		specify the audio encoder. (audio option)
ffmpegother	AudioSamplingRate	-ar=1		Set the audio sampling frequency. For output streams it is set by default to the frequency of the corresponding input stream. For input streams this option only makes sense for audio grabbing devices and raw demuxers and is mapped to the corresponding demuxer options.  (audio option)
ffmpegother	Bitrate	-b=1		Bitrates.  -b:a for audio stream and -b:v for video stream
ffmpegother	Coder	-coder=1 		
ffmpegother	Flags	-flags=1 		
ffmpegother	Cmp	-cmp=1 		
ffmpegother	Partition	-partitions=1 		
ffmpegother	MotionEstimateMethod	-me_method=1,5 		
ffmpegother	SPQuality	-subq=1 sub-pel 		
ffmpegother	MERange	-me_range=1,0 		
ffmpegother	GOP	-g=1,12 		
ffmpegother	MinInterval	-keyint_min=1,25 		
ffmpegother	Scene change threshold	-sc_threshold=1,0 		
ffmpegother	QP factor	-i_qfactor=1,-.8 		
ffmpegother	I,P,B Strategy	-b_strategy=1,0 		
ffmpegother	Threads	-threads=1,1 		
ffmpegother	FormatA -af			
ffmpegother	FormatV	-vf		
ffmpegother	3DO STR	   -f  3dostr		
ffmpegformat	3GP2 (3GPP2 file format)	   -f 3g2		
ffmpegformat	3GP (3GPP file format)	   -f 3gp		
ffmpegformat	4X Technologies 	   -f 4xm		
ffmpegformat	a64 - video for Commodore 64 	   -f a64		
ffmpegformat	Audible AA format files 	   -f aa		
ffmpegformat	raw ADTS AAC (Advanced Audio Coding) 	   -f aac		
ffmpegformat	raw AC-3 	   -f ac3		
ffmpegformat	Interplay ACM 	   -f acm		
ffmpegformat	ACT Voice file format 	   -f act		
ffmpegformat	Artworx Data Format 	   -f adf		
ffmpegformat	ADP 	   -f adp		
ffmpegformat	Sony PS2 ADS 	   -f ads		
ffmpegformat	ADTS AAC (Advanced Audio Coding) 	   -f adts		
ffmpegformat	CRI ADX 	   -f adx		
ffmpegformat	MD STUDIO audio 	   -f aea		
ffmpegformat	AFC 	   -f afc		
ffmpegformat	Audio IFF 	   -f aiff		
ffmpegformat	CRI AIX 	   -f aix		
ffmpegformat	PCM A-law 	   -f alaw		
ffmpegformat	Alias/Wavefront PIX image 	   -f alias_pix		
ffmpegformat	3GPP AMR 	   -f amr		
ffmpegformat	raw AMR-NB 	   -f amrnb		
ffmpegformat	raw AMR-WB 	   -f amrwb		
ffmpegformat	Deluxe Paint Animation 	   -f anm		
ffmpegformat	CRYO APC 	   -f apc		
ffmpegformat	Monkey's Audio 	   -f ape		
ffmpegformat	Animated Portable Network Graphics 	   -f apng		
ffmpegformat	raw aptX (Audio Processing Technology for Bluetooth) 	   -f aptx		
ffmpegformat	raw aptX HD (Audio Processing Technology for Bluetooth) 	   -f aptx_hd		
ffmpegformat	AQTitle subtitles 	   -f aqtitle		
ffmpegformat	ASF (Advanced / Active Streaming Format) 	   -f asf		
ffmpegformat	ASF (Advanced / Active Streaming Format) 	   -f asf_o		
ffmpegformat	ASF (Advanced / Active Streaming Format) 	   -f asf_stream		
ffmpegformat	SSA (SubStation Alpha) subtitle 	   -f ass		
ffmpegformat	AST (Audio Stream) 	   -f ast		
ffmpegformat	Sun AU 	   -f au		
ffmpegformat	AVI (Audio Video Interleaved) 	   -f avi		
ffmpegformat	AviSynth script 	   -f avisynth		
ffmpegformat	SWF (ShockWave Flash) (AVM2) 	   -f avm2		
ffmpegformat	AVR (Audio Visual Research) 	   -f avr		
ffmpegformat	Argonaut Games Creature Shock 	   -f avs		
ffmpegformat	raw AVS2-P2/IEEE1857.4 video 	   -f avs2		
ffmpegformat	Bethesda Softworks VID 	   -f bethsoftvi		
ffmpegformat	Brute Force & Ignorance 	   -f bfi		
ffmpegformat	BFSTM (Binary Cafe Stream) 	   -f bfstm		
ffmpegformat	Binary text 	   -f bin		
ffmpegformat	Bink 	   -f bink		
ffmpegformat	ffmpegformat	G.729 BIT file format 		
ffmpegformat	piped bmp sequence 	   -f bmp_pipe		
ffmpegformat	Discworld II BMV 	   -f bmv		
ffmpegformat	Black Ops Audio 	   -f boa		
ffmpegformat	BRender PIX image 	   -f brender_pi		
ffmpegformat	BRSTM (Binary Revolution Stream) 	   -f brstm		
ffmpegformat	Interplay C93 	   -f c93		
ffmpegformat	Apple CAF (Core Audio Format) 	   -f caf		
ffmpegformat	raw Chinese AVS (Audio Video Standard) video 	   -f cavsvideo		
ffmpegformat	CD Graphics 	   -f cdg		
ffmpegformat	Commodore CDXL video 	   -f cdxl		
ffmpegformat	Phantom Cine 	   -f cine		
ffmpegformat	codec2 .c2 muxer 	   -f codec2		
ffmpegformat	raw codec2 muxer 	   -f codec2raw		
ffmpegformat	Virtual concatenation script 	   -f concat		
ffmpegformat	CRC testing 	   -f crc		
ffmpegformat	DASH Muxer 	   -f dash		
ffmpegformat	raw data 	   -f data		
ffmpegformat	D-Cinema audio 	   -f daud		
ffmpegformat	Sega DC STR 	   -f dcstr		
ffmpegformat	piped dds sequence 	   -f dds_pipe		
ffmpegformat	Chronomaster DFA 	   -f dfa		
ffmpegformat	raw Dirac 	   -f dirac		
ffmpegformat	raw DNxHD (SMPTE VC-3) 	   -f dnxhd		
ffmpegformat	piped dpx sequence 	   -f dpx_pipe		
ffmpegformat	DSD Stream File (DSF) 	   -f dsf		
ffmpegformat	DirectShow capture 	   -f dshow		
ffmpegformat	Delphine Software International CIN 	   -f dsicin		
ffmpegformat	Digital Speech Standard (DSS) 	   -f dss		
ffmpegformat	raw DTS 	   -f dts		
ffmpegformat	raw DTS-HD 	   -f dtshd		
ffmpegformat	DV (Digital Video) 	   -f dv		
ffmpegformat	raw dvbsub 	   -f dvbsub		
ffmpegformat	dvbtxt 	   -f dvbtxt		
ffmpegformat	MPEG-2 PS (DVD VOB) 	   -f dvd		
ffmpegformat	DXA 	   -f dxa		
ffmpegformat	Electronic Arts Multimedia 	   -f ea		
ffmpegformat	Electronic Arts cdata 	   -f ea_cdata		
ffmpegformat	raw E-AC-3 	   -f eac3		
ffmpegformat	Ensoniq Paris Audio File 	   -f epaf		
ffmpegformat	piped exr sequence 	   -f exr_pipe		
ffmpegformat	PCM 32-bit floating-point big-endian 	   -f f32be		
ffmpegformat	PCM 32-bit floating-point little-endian 	   -f f32le		
ffmpegformat	F4V Adobe Flash Video 	   -f f4v		
ffmpegformat	PCM 64-bit floating-point big-endian 	   -f f64be		
ffmpegformat	PCM 64-bit floating-point little-endian 	   -f f64le		
ffmpegformat	FFmpeg metadata in text 	   -f ffmetadata		
ffmpegformat	FIFO queue pseudo-muxer 	   -f fifo		
ffmpegformat	Fifo test muxer 	   -f fifo_test		
ffmpegformat	Sega FILM / CPK 	   -f film_cpk		
ffmpegformat	Adobe Filmstrip 	   -f filmstrip		
ffmpegformat	Flexible Image Transport System 	   -f fits		
ffmpegformat	raw FLAC 	   -f flac		
ffmpegformat	FLI/FLC/FLX animation 	   -f flic		
ffmpegformat	FLV (Flash Video) 	   -f flv		
ffmpegformat	framecrc testing 	   -f framecrc		
ffmpegformat	Per-frame hash testing 	   -f framehash		
ffmpegformat	Per-frame MD5 testing 	   -f framemd5		
ffmpegformat	Megalux Frame 	   -f frm		
ffmpegformat	FMOD Sample Bank 	   -f fsb		
ffmpegformat	raw G.722 	   -f g722		
ffmpegformat	raw G.723.1 	   -f g723_1		
ffmpegformat	raw big-endian G.726 ("left-justified") 	   -f g726		
ffmpegformat	raw little-endian G.726 ("right-justified") 	   -f g726le		
ffmpegformat	G.729 raw format demuxer 	   -f g729		
ffmpegformat	GDI API Windows frame grabber 	   -f gdigrab		
ffmpegformat	Gremlin Digital Video 	   -f gdv		
ffmpegformat	GENeric Header 	   -f genh		
ffmpegformat	GIF Animation 	   -f gif		
ffmpegformat	raw GSM 	   -f gsm		
ffmpegformat	GXF (General eXchange Format) 	   -f gxf		
ffmpegformat	raw H.261 	   -f h261		
ffmpegformat	raw H.263 	   -f h263		
ffmpegformat	raw H.264 video 	   -f h264		
ffmpegformat	Hash testing 	   -f hash		
ffmpegformat	HDS Muxer 	   -f hds		
ffmpegformat	raw HEVC video 	   -f hevc		
ffmpegformat	Apple HTTP Live Streaming0 	   -f hls		
ffmpegformat	Apple HTTP Live Streaming 	   -f hls,appleh		
ffmpegformat	Cryo HNM v4 	   -f hnm		
ffmpegformat	Microsoft Windows ICO 	   -f ico		
ffmpegformat	id Cinematic 	   -f idcin		
ffmpegformat	iCE Draw File 	   -f idf		
ffmpegformat	IFF (Interchange File Format) 	   -f iff		
ffmpegformat	iLBC storage 	   -f ilbc		
ffmpegformat	image2 sequence 	   -f image2		
ffmpegformat	piped image2 sequence 	   -f image2pipe		
ffmpegformat	raw Ingenient MJPEG 	   -f ingenient		
ffmpegformat	Interplay MVE 	   -f ipmovie		
ffmpegformat	iPod H.264 MP4 (MPEG-4 Part 14) 	   -f ipod		
ffmpegformat	Berkeley/IRCAM/CARL Sound Format 	   -f ircam		
ffmpegformat	ISMV/ISMA (Smooth Streaming) 	   -f ismv		
ffmpegformat	Funcom ISS 	   -f iss		
ffmpegformat	IndigoVision 8000 video 	   -f iv8		
ffmpegformat	On2 IVF 	   -f ivf		
ffmpegformat	IVR (Internet Video Recording) 	   -f ivr		
ffmpegformat	piped j2k sequence 	   -f j2k_pipe		
ffmpegformat	JACOsub subtitle format 	   -f jacosub		
ffmpegformat	piped jpeg sequence 	   -f jpeg_pipe		
ffmpegformat	piped jpegls sequence 	   -f jpegls_pipe		
ffmpegformat	Bitmap Brothers JV 	   -f jv		
ffmpegformat	LOAS/LATM 	   -f latm		
ffmpegformat	Libavfilter virtual input device 	   -f lavfi		
ffmpegformat	live RTMP FLV (Flash Video) 	   -f live_flv		
ffmpegformat	raw lmlm4 	   -f lmlm4		
ffmpegformat	LOAS AudioSyncStream 	   -f loas		
ffmpegformat	LRC lyrics 	   -f lrc		
ffmpegformat	LVF 	   -f lvf		
ffmpegformat	VR native stream (LXF) 	   -f lxf		
ffmpegformat	raw MPEG-4 video 	   -f m4v		
ffmpegformat	Matroska 	   -f matroska		
ffmpegformat	Matroska / WebM 	   -f matroska,webm		
ffmpegformat	MD5 testing 	   -f md5		
ffmpegformat	Metal Gear Solid 	   -f  The Twin Snakes:mgsts		
ffmpegformat	MicroDVD subtitle format 	   -f microdvd		
ffmpegformat	raw MJPEG video 	   -f mjpeg		
ffmpegformat	raw MJPEG 2000 video 	   -f mjpeg_2000		
ffmpegformat	extract pts as timecode v2 format, as defined by mkvtoolnix 	   -f mkvtimestamp_v2		
ffmpegformat	raw MLP 	   -f mlp		
ffmpegformat	Magic Lantern Video (MLV) 	   -f mlv		
ffmpegformat	American Laser Games MM 	   -f mm		
ffmpegformat	Yamaha SMAF 	   -f mmf		
ffmpegformat	QuickTime / MOV 	   -f mov		
ffmpegformat	3g2,mj2 QuickTime / MOV 	   -f mov,mp4,m4a,3gp,3g2,mj2		
ffmpegformat	MP2 (MPEG audio layer 2) 	   -f mp2		
ffmpegformat	MP3 (MPEG audio layer 3) 	   -f mp3		
ffmpegformat	MP4 (MPEG-4 Part 14) 	   -f mp4		
ffmpegformat	Musepack 	   -f mpc		
ffmpegformat	Musepack SV8 	   -f mpc8		
ffmpegformat	MPEG-1 Systems / MPEG program stream 	   -f mpeg		
ffmpegformat	raw MPEG-1 video 	   -f mpeg1video		
ffmpegformat	raw MPEG-2 video 	   -f mpeg2video		
ffmpegformat	MPEG-TS (MPEG-2 Transport Stream) 	   -f mpegts		
ffmpegformat	raw MPEG-TS (MPEG-2 Transport Stream) 	   -f mpegtsraw		
ffmpegformat	raw MPEG video 	   -f mpegvideo		
ffmpegformat	MIME multipart JPEG 	   -f mpjpeg		
ffmpegformat	MPL2 subtitles 	   -f mpl2		
ffmpegformat	MPlayer subtitles 	   -f mpsub		
ffmpegformat	Sony PS3 MSF 	   -f msf		
ffmpegformat	MSN TCP Webcam stream 	   -f msnwctcp		
ffmpegformat	Konami PS2 MTAF 	   -f mtaf		
ffmpegformat	MTV 	   -f mtv		
ffmpegformat	PCM mu-law 	   -f mulaw		
ffmpegformat	Eurocom MUSX 	   -f musx		
ffmpegformat	Silicon Graphics Movie 	   -f mv		
ffmpegformat	Motion Pixels MVI 	   -f mvi		
ffmpegformat	MXF (Material eXchange Format) 	   -f mxf		
ffmpegformat	MXF (Material eXchange Format) D-10 Mapping 	   -f mxf_d10		
ffmpegformat	MXF (Material eXchange Format) Operational Pattern Atom 	   -f mxf_opatom		
ffmpegformat	MxPEG clip 	   -f mxg		
ffmpegformat	NC camera feed 	   -f nc		
ffmpegformat	NIST SPeech HEader REsources 	   -f nistsphere		
ffmpegformat	Computerized Speech Lab NSP 	   -f nsp		
ffmpegformat	Nullsoft Streaming Video 	   -f nsv		
ffmpegformat	raw null video 	   -f null		
ffmpegformat	NUT 	   -f nut		
ffmpegformat	NuppelVideo 	   -f nuv		
ffmpegformat	Ogg Audio 	   -f oga		
ffmpegformat	Ogg 	   -f ogg		
ffmpegformat	Ogg Video 	   -f ogv		
ffmpegformat	Sony OpenMG audio 	   -f oma		
ffmpegformat	Ogg Opus 	   -f opus		
ffmpegformat	Amazing Studio Packed Animation File 	   -f paf		
ffmpegformat	piped pam sequence 	   -f pam_pipe		
ffmpegformat	piped pbm sequence 	   -f pbm_pipe		
ffmpegformat	piped pcx sequence 	   -f pcx_pipe		
ffmpegformat	piped pgm sequence 	   -f pgm_pipe		
ffmpegformat	piped pgmyuv sequence 	   -f pgmyuv_pip		
ffmpegformat	piped pictor sequence 	   -f pictor_pip		
ffmpegformat	PJS (Phoenix Japanimation Society) subtitles 	   -f pjs		
ffmpegformat	Playstation Portable PMP 	   -f pmp		
ffmpegformat	piped png sequence 	   -f png_pipe		
ffmpegformat	piped ppm sequence 	   -f ppm_pipe		
ffmpegformat	piped psd sequence 	   -f psd_pipe		
ffmpegformat	PSP MP4 (MPEG-4 Part 14) 	   -f psp		
ffmpegformat	Sony Playstation STR 	   -f psxstr		
ffmpegformat	TechnoTrend PVA 	   -f pva		
ffmpegformat	PVF (Portable Voice Format) 	   -f pvf		
ffmpegformat	QCP 	   -f qcp		
ffmpegformat	piped qdraw sequence 	   -f qdraw_pipe		
ffmpegformat	REDCODE R3D 	   -f r3d		
ffmpegformat	raw video 	   -f rawvideo		
ffmpegformat	RealText subtitle format 	   -f realtext		
ffmpegformat	RedSpark 	   -f redspark		
ffmpegformat	RL2 	   -f rl2		
ffmpegformat	RealMedia 	   -f rm		
ffmpegformat	raw id RoQ 	   -f roq		
ffmpegformat	RPL / ARMovie 	   -f rpl		
ffmpegformat	GameCube RSD 	   -f rsd		
ffmpegformat	Lego Mindstorms RSO 	   -f rso		
ffmpegformat	RTP output 	   -f rtp		
ffmpegformat	RTP/mpegts output format 	   -f rtp_mpegts		
ffmpegformat	RTSP output 	   -f rtsp		
ffmpegformat	PCM signed 16-bit big-endian 	   -f s16be		
ffmpegformat	PCM signed 16-bit little-endian 	   -f s16le		
ffmpegformat	PCM signed 24-bit big-endian 	   -f s24be		
ffmpegformat	PCM signed 24-bit little-endian 	   -f s24le		
ffmpegformat	PCM signed 32-bit big-endian 	   -f s32be		
ffmpegformat	PCM signed 32-bit little-endian 	   -f s32le		
ffmpegformat	SMPTE 337M 	   -f s337m		
ffmpegformat	PCM signed 8-bit 	   -f s8		
ffmpegformat	SAMI subtitle format 	   -f sami		
ffmpegformat	SAP output 	   -f sap		
ffmpegformat	raw SBC 	   -f sbc		
ffmpegformat	SBaGen binaural beats script 	   -f sbg		
ffmpegformat	Scenarist Closed Captions 	   -f scc		
ffmpegformat	SDL2 output device 	   -f sdl,sdl2		
ffmpegformat	SDP 	   -f sdp		
ffmpegformat	SDR2 	   -f sdr2		
ffmpegformat	MIDI Sample Dump Standard 	   -f sds		
ffmpegformat	Sample Dump eXchange 	   -f sdx		
ffmpegformat	segment 	   -f segment		
ffmpegformat	piped sgi sequence 	   -f sgi_pipe		
ffmpegformat	raw Shorten 	   -f shn		
ffmpegformat	Beam Software SIFF 	   -f siff		
ffmpegformat	JPEG single image 	   -f singlejpeg		
ffmpegformat	Asterisk raw pcm 	   -f sln		
ffmpegformat	Loki SDL MJPEG 	   -f smjpeg		
ffmpegformat	Smacker 	   -f smk		
ffmpegformat	Smooth Streaming Muxer 	   -f smoothstreaming		
ffmpegformat	LucasArts Smush 	   -f smush		
ffmpegformat	Sierra SOL 	   -f sol		
ffmpegformat	SoX native 	   -f sox		
ffmpegformat	IEC 61937 (used on S/PDIF - IEC958) 	   -f spdif		
ffmpegformat	Ogg Speex 	   -f spx		
ffmpegformat	SubRip subtitle 	   -f srt		
ffmpegformat	Spruce subtitle format 	   -f stl		
ffmpegformat	segment streaming segment muxer 	   -f stream_segment,ssegment		
ffmpegformat	SubViewer subtitle format 	   -f subviewer		
ffmpegformat	SubViewer v1 subtitle format 	   -f subviewer1		
ffmpegformat	piped sunrast sequence 	   -f sunrast_pipe		
ffmpegformat	raw HDMV Presentation Graphic Stream subtitles 	   -f sup		
ffmpegformat	Konami PS2 SVAG 	   -f svag		
ffmpegformat	MPEG-2 PS (SVCD) 	   -f svcd		
ffmpegformat	piped svg sequence 	   -f svg_pipe		
ffmpegformat	SWF (ShockWave Flash) 	   -f swf		
ffmpegformat	raw TAK 	   -f tak		
ffmpegformat	TED Talks captions 	   -f tedcaptions		
ffmpegformat	Multiple muxer tee 	   -f tee		
ffmpegformat	THP 	   -f thp		
ffmpegformat	Tiertex Limited SEQ 	   -f tiertexseq		
ffmpegformat	piped tiff sequence 	   -f tiff_pipe		
ffmpegformat	8088flex TMV 	   -f tmv		
ffmpegformat	raw TrueHD 	   -f truehd		
ffmpegformat	TTA (True Audio) 	   -f tta		
ffmpegformat	Tele-typewriter 	   -f tty		
ffmpegformat	Renderware TeXture Dictionary 	   -f txd		
ffmpegformat	TiVo TY Stream 	   -f ty		
ffmpegformat	PCM unsigned 16-bit big-endian 	   -f u16be		
ffmpegformat	PCM unsigned 16-bit little-endian 	   -f u16le		
ffmpegformat	PCM unsigned 24-bit big-endian 	   -f u24be		
ffmpegformat	PCM unsigned 24-bit little-endian 	   -f u24le		
ffmpegformat	PCM unsigned 32-bit big-endian 	   -f u32be		
ffmpegformat	PCM unsigned 32-bit little-endian 	   -f u32le		
ffmpegformat	PCM unsigned 8-bit 	   -f u8		
ffmpegformat	uncoded framecrc testing 	   -f uncodedfra		
ffmpegformat	Uncompressed 4    -f 2    -f 2 10-bit 	   -f v210		
ffmpegformat	Uncompressed 4:2:2 10-bit 	   -f v210x		
ffmpegformat	Sony PS2 VAG 	   -f vag		
ffmpegformat	raw VC-1 video 	   -f vc1		
ffmpegformat	VC-1 test bitstream 	   -f vc1test		
ffmpegformat	MPEG-1 Systems / MPEG program stream (VCD) 	   -f vcd		
ffmpegformat	VfW video capture 	   -f vfwcap		
ffmpegformat	Vivo 	   -f vivo		
ffmpegformat	Sierra VMD 	   -f vmd		
ffmpegformat	MPEG-2 PS (VOB) 	   -f vob		
ffmpegformat	VobSub subtitle format 	   -f vobsub		
ffmpegformat	Creative Voice 	   -f voc		
ffmpegformat	Sony PS2 VPK 	   -f vpk		
ffmpegformat	VPlayer subtitles 	   -f vplayer		
ffmpegformat	Nippon Telegraph and Telephone Corporation (NTT) TwinVQ 	   -f vqf		
ffmpegformat	Sony Wave64 	   -f w64		
ffmpegformat	WAV / WAVE (Waveform Audio) 	   -f wav		
ffmpegformat	Wing Commander III movie 	   -f wc3movie		
ffmpegformat	WebM 	   -f webm		
ffmpegformat	WebM Chunk Muxer 	   -f webm_chunk		
ffmpegformat	st WebM DASH Manifest 	   -f webm_dash_		
ffmpegformat	WebP 	   -f webp		
ffmpegformat	piped webp sequence 	   -f webp_pipe		
ffmpegformat	WebVTT subtitle 	   -f webvtt		
ffmpegformat	Westwood Studios audio 	   -f wsaud		
ffmpegformat	Wideband Single-bit Data (WSD) 	   -f wsd		
ffmpegformat	Westwood Studios VQA 	   -f wsvqa		
ffmpegformat	Windows Television (WTV) 	   -f wtv		
ffmpegformat	raw WavPack 	   -f wv		
ffmpegformat	Psion 3 audio 	   -f wve		
ffmpegformat	Maxis XA 	   -f xa		
ffmpegformat	eXtended BINary text (XBIN) 	   -f xbin		
ffmpegformat	Microsoft XMV 	   -f xmv		
ffmpegformat	piped xpm sequence 	   -f xpm_pipe		
ffmpegformat	Sony PS3 XVAG 	   -f xvag		
ffmpegformat	piped xwd sequence 	   -f xwd_pipe		
ffmpegformat	Microsoft xWMA 	   -f xwma		
ffmpegformat	Psygnosis YOP 	   -f yop$		
ffmpegformat	YUV4MPEG pipe 	   -f yuv4mpegpipe		
ffmpegvfilter	alphaextract	::Extract the alpha component from the input as a grayscale video. This is especially useful with the alphamerge filter.		
ffmpegvfilter	Amplify	:2:Amplify differences between current pixel and pixels of adjacent frames in same pixel location.\radius:2:Set frame radius. Allowed range is from 1 to 63. For example radius of 3 will instruct filter to calculate average of 7 frames.\factor:2:Set factor to amplify difference.  Allowed range is from 0 to 65535.\threshold:10:Set threshold for difference amplification. Any differrence greater or equal to this value will not alter source pixel.  Allowed range is from 0 to 65535.\low::Set lower limit for changing source pixel. Allowed range is from 0 to 65535. This option controls maximum possible value that will decrease source pixel value.\high:65535:Set high limit for changing source pixel.  Allowed range is from 0 to 65535. This option controls maximum possible value that will increase source pixel value.\planes::Set which planes to filter. Default is all. Allowed range is from 0 to 15.		
ffmpegvfilter	ass	:auto:Same as the subtitles filter, except that it doesn’t require libavcodec and libavformat to work. On the other hand, it is limited to ASS (Advanced Substation Alpha) subtitles files.		
ffmpegvfilter	shaping	:auto:Set the shaping engine,Available values are:‘auto’ The default libass shaping engine, which is the best available. ‘simple’ Fast, font-agnostic shaper that can do only substitutions ‘complex’ Slower shaper using OpenType for substitutions and positioning. The default is auto.		
ffmpegvfilter	atadenoise	::Apply an Adaptive Temporal Averaging Denoiser to the video input.\0a:0.02:Set threshold A for 1st plane. Default is 0.02. Valid range is 0 to 0.3.\0b:0.04:Set threshold B for 1st plane. Default is 0.04. Valid range is 0 to 5.\1a:0.02:Set threshold A for 2nd plane. Default is 0.02. Valid range is 0 to 0.3.\1b:0.04:Set threshold B for 2nd plane. Default is 0.04. Valid range is 0 to 5.\2a:0.02:Set threshold A for 3rd plane. Default is 0.02. Valid range is 0 to 0.3.\2b:0.04:Set threshold B for 3rd plane. Default is 0.04. Valid range is 0 to 5. Threshold A is designed to react on abrupt changes in the input signal and threshold B is designed to react on continuous changes in the input signal.\s:9:Set number of frames filter will use for averaging. Default is 9. Must be odd number in range [5, 129].\p::Set what planes of frame filter will use for averaging. Default is all.		
ffmpegvfilter	avgblur	::Apply average blur filter.\sizeX::Set horizontal radius size.\sizeY:0:Set vertical radius size, if zero it will be same as sizeX.\planes::Set which planes to filter. By default all planes are filtered.		
ffmpegvfilter	bbox	::Compute the bounding box for the non-black pixels in the input frame luminance plane.This filter computes the bounding box containing all the pixels with a luminance value greater than the minimum allowed value. The parameters describing the bounding box are printed on the filter log.\min_val:16:Set the minimal luminance value.\bitplanenoise::Show and measure bit plane noise.\bitplane:1:Set which plane to analyze.\filter::Filter out noisy pixels from bitplane set above. Default is disabled.		
ffmpegvfilter	blackdetect	::Detect video intervals that are (almost) completely black. Can be useful to detect chapter transitions, commercials, or invalid recordings. Output lines contains the time for the start, end and duration of the detected black interval expressed in seconds.In order to display the output lines, you need to set the loglevel at least to the AV_LOG_INFO value.\black_min_duration:2.0:Set the minimum detected black duration expressed in seconds. It must be a non-negative floating point number.\picture_black_ratio_th, pic_th:0.98:Set the threshold for considering a picture "black". Express the minimum value for the ratio: nb_black_pixels / nb_pixels for which a picture is considered black.\pixel_black_th:0.10:Set the threshold for considering a pixel "black". The threshold expresses the maximum pixel luminance value for hich a pixel is considered "black". The provided value is scaled according to the following equation: absolute_threshold = luminance_minimum_value + pixel_black_th * luminance_range_size. luminance_range_size and luminance_minimum_value depend on the input video format, the range is [0-255] for YUV full-range formats and [16-235] for YUV non full-range formats. The following example sets the maximum pixel threshold to the minimum value, and detects only black intervals of 2 or more seconds  blackdetect=d=2:pix_th=0.00		
ffmpegvfilter	blackframe	::Detect frames that are (almost) completely black. Can be useful to detect chapter transitions or commercials. Output lines consist of the frame number of the detected frame, the percentage of blackness, the position in the file if known or -1 and the timestamp in seconds. In order to display the output lines, you need to set the loglevel at least to the AV_LOG_INFO value. This filter exports frame metadata lavfi.blackframe.pblack. The value represents the percentage of pixels in the picture that are below the threshold value.\amount:98:The percentage of the pixels that have to be below the threshold.\threshold:32:The threshold below which a pixel value is considered black.		
ffmpegvfilter	blend	::Blend two video frames into each other. The blend filter takes two input streams and outputs one stream, the first input is the "top" layer and second input is "bottom" layer. By default, the output terminates when the longest input terminates. The tblend (time blend) filter takes two consecutive frames from one single stream, and outputs the result obtained by blending the new frame on top of the old frame. Available values for component modes are: ‘addition’,‘grainmerge’,‘and’,‘average’,‘burn’,‘darken’,‘difference’,‘grainextract’,‘divide’,‘dodge’,‘freeze’,‘exclusion’,‘extremity’,‘glow’,‘hardlight’,‘hardmix’,‘heat’,‘lighten’,‘li,earlight’,‘multiply’,‘multiply128’,‘negation’,‘normal’,‘or’,‘overlay’,‘phoenix’,‘pinlight’‘reflect’,‘screen’,‘softlight’,‘subtract’,‘vividlight’,‘xor’,,c0_opacityc1_opacity,c2_opacity,c3_opacity,all_opacity. Set blend opacity for specific pixel component or all pixel components in case of all_opacity. Only used in combination with pixel component blend modes. c0_expr,c1_expr,c2_expr,c3_expr,all_expr. Set blend expression for specific pixel component or all pixel components in case of all_expr. Note that related mode options will be ignored if those are set.The blend filter also supports the framesync options. Examples 1)Apply transition from bottom layer to top layer in first 10 seconds: blend=all_expr='A*(if(gte(T,10),1,T/10))+B*(1-(if(gte(T,10),1,T/10)))' 2) Apply linear horizontal transition from top layer to bottom layer:blend=all_expr='A*(X/W)+B*(1-X/W)' 3: Apply 1x1 checkerboard effect:blend=all_expr='if(eq(mod(X,2),mod(Y,2)),A,B)' 4) Apply uncover left effect: blend=all_expr='if(gte(N*SW+X,W),A,B)' 5) Apply uncover down effect: blend=all_expr='if(gte(Y-N*SH,0),A,B)' 6) Apply uncover up-left effect: blend=all_expr='if(gte(T*SH*40+Y,H)*gte((T*40*SW+X)*W/H,W),A,B)' 7) Split diagonally video and shows top and bottom layer on each side: blend=all_expr='if(gt(X,Y*(W/H)),A,B)' 8) Display differences between the current and the previous frame: blend=all_mode=grainextract\c0_mode::\ c1_mode::\c2_mode::\c3_mode::\all_mode::Default value is normal.\N::The sequential number of the filtered frame, starting from 0.\X::x  coordinate of the current sample\Y::y  coordinate of the current sample\W::width of currently filtered plane\H::height of currently filtered plane\SW::Width scale for the plane being filtered. It is the ratio between the dimensions of the current plane to the luma plane, e.g. for a yuv420p frame, the values are 1 for the luma plane and 0.5  for the chroma planes.\SH::Height scale for the plane being filtered. It is the ratio between the dimensions of the current plane to the luma plane, e.g. for a yuv420p frame, the values are 1 for the luma plane and 0.5for the chroma planes.\T::Time of the current frame, expressed in seconds.\TOP::Value of pixel component at current location for first video frame (top layer).\BOTTOM::Value of pixel component at current location for second video frame (bottom layer).		
ffmpegvfilter	bm3d	::Denoise frames using Block-Matching 3D algorithm. Examples Basic filtering with bm3d: 1 bm3d=sigma=3:block=4:bstep=2:group=1:estim=basic 2 Same as above, but filtering only luma: d=sigma=3:block=4:bstep=2:group=1:estim=basic:planes=1  3 Same as above, but with both estimation modes: split[a][b],[a]bm3d=sigma=3:block=4:bstep=2:group=1:estim=basic[a],[b][a]bm3d=sigma=3:block=4:bstep=2:group=16:estim=final:ref=1Same as above, but prefilter with nlmeans filter instead: split[a][b],[a]nlmeans=s=3:r=7:p=3[a],[b][a]bm3d=sigma=3:block=4:bstep=2:group=16:estim=final:ref=1\sigma:1:Set denoising strength. Allowed range is from 0 to 999.9. The denoising algorith is very sensitive to sigma, so adjust it according to the source.\block::Set local patch size. This sets dimensions in 2D.\bstep:4:Set sliding step for processing blocks. Allowed range is from 1 to 64. Smaller values allows processing more reference blocks and is slower.\group:1:Set maximal number of similar blocks for 3rd dimension. Default value is 1. When set to 1, no block matching is done. Larger values allows more blocks in single group. Allowed range is from 1 to 256.\range:9:Set radius for search block matching. Default is 9. Allowed range is from 1 to INT32_MAX.\mstep:1:Set step between two search locations for block matching. Default is 1. Allowed range is from 1 to 64. Smaller is slower.\thmse::Set threshold of mean square error for block matching. Valid range is 0 to INT32_MAX.\hdthr::Set thresholding parameter for hard thresholding in 3D transformed domain. Larger values results in stronger hard-thresholding filtering in frequency domain.\estim::Set filtering estimation mode. Can be basic or final. Default is basic.\ref::If enabled, filter will use 2nd stream for block matching. Default is disabled for basic value of estim option, and always enabled if value of estim is final.\planes::Set planes to filter. Default is all available except alpha.		
ffmpegvfilter	boxblur	::Apply a boxblur algorithm to the input video. The expressions can contain the following constants: w,h The input width and height in pixels. cw,ch The input chroma image width and height in pixels. hsub,vsub The horizontal and vertical chroma subsample values. For example, for the pixel format "yuv422p", hsub is 2 and vsub is 1. Examples 1 Apply a boxblur filter with the luma, chroma, and alpha radii set to 2: boxblur=luma_radius=2:luma_power=1 2 boxblur=2:1 2)Set the luma radius to 2, and alpha and chroma radius to 0: boxblur=2:1:cr=0:ar=0 3) Set the luma and chroma radii to a fraction of the video dimension: boxblur=luma_radius=min(h,w)/10:luma_power=1:chroma_radius=min(cw,ch)/10:chroma_power=1 \luma_radius:2:The radius value must be a non-negative number, and must not be greater than the value of the expression min(w,h)/2 for the luma and alpha planes, and of min(cw,ch)/2 for the chroma planes. Default value for luma_radius is "2". If not specified, chroma_radius and alpha_radius default to the corresponding value set for luma_radius. \chroma_radius:: \alpha_radius::Set an expression for the box radius in pixels used for blurring the corresponding input plane.\luma_power:2:If not specified, chroma_power and alpha_power default to the corresponding value set for luma_power.\chroma_power:: \alpha_power::Specify how many times the boxblur filter is applied to the corresponding plane.		
ffmpegvfilter	bwdif	::Deinterlace the input video ("bwdif" stands for "Bob Weaver Deinterlacing Filter"). Motion adaptive deinterlacing based on yadif with the use of w3fdif and c)ubic interpolation algorithms.\mode:send_field:The interlacing mode to adopt. It accepts one of the following values: 0, send_frame-Output one frame for each frame. 1, send_field-Output one frame for each field.\parity:-1:The picture field parity assumed for the input interlaced video. It accepts one of the following values: 0, tff-Assume the top field is first. 1, bff-Assume the bottom field is first. -1, auto-Enable automatic detection of field parity. The default value is auto. If the interlacing is unknown or the decoder does not export this information, top field first will be assumed.\deint:0:Specify which frames to deinterlace. Accept one of the following values: 0, all-Deinterlace all frames. 1, interlaced-Only deinterlace frames marked as interlaced.		
ffmpegvfilter	chromahold	::Remove all color information for all colors except for certain one.\color::The color which will not be replaced with neutral chroma.\similarity::Similarity percentage with the above color. 0.01 matches only the exact key color, while 1.0 matches everything.\yuv::Signals that the color passed is already in YUV instead of RGB. Literal colors like "green" or "red" don’t make sense with this enabled anymore. This can be used to pass exact YUV values as hexadecimal numbers.		
ffmpegvfilter	chromakey	::YUV colorspace color/chroma keying. Examples 1) Make every green pixel in the input image transparent: ffmpeg -i input.png -vf chromakey=green out.png 2) Overlay a greenscreen-video on top of a static black background. ffmpeg -f lavfi -i color=c=black:s=1280x720 -i video.mp4 -shortest -filter_complex "[1:v]chromakey=0x70de77:0.1:0.2[ckout];[0:v][ckout]overlay[out]" -map "[out]" output.mkv\color::The color which will be replaced with transparency.\similarity::Similarity percentage with the key color. 0.01 matches only the exact key color, while 1.0 matches everything.\blend::Blend percentage. 0.0 makes pixels either fully transparent, or not transparent at all.Higher values result in semi-transparent pixels, with a higher transparency the more similar the pixels color is to the key color.\yuv::Signals that the color passed is already in YUV instead of RGB.Literal colors like "green" or "red" don’t make sense with this enabled anymore. This can be used to pass exact YUV values as hexadecimal numbers.		
ffmpegvfilter	chromashift	::Shift chroma pixels horizontally and/or vertically.\cbh::Set amount to shift chroma-blue horizontally.\cbv::Set amount to shift chroma-blue vertically.\crh::Set amount to shift chroma-red horizontally.\crv::Set amount to shift chroma-red vertically.\edge::Set edge mode, can be smear, default, or warp.		
ffmpegvfilter	ciescope	::Display CIE color diagram with pixels overlaid onto it.\system::Set color system.‘ntsc, 470m’ ‘ebu, 470bg’ ‘smpte’ ‘240m’ ‘apple’ ‘widergb’ ‘cie1931’ ‘rec709, hdtv’ ‘uhdtv, rec2020’\cie::Set CIE System ‘xyy’ ‘ucs’ ‘luv’\gamuts::Set what gamuts to draw. See system option for available values.\size:512:Set ciescope size, by default set to 512.\intensity::Set intensity used to map input pixel values to CIE diagram.\contrast::Set contrast used to draw tongue colors that are out of active color system gamut.\corrgamma::Correct gamma displayed on scope, by default enabled.\showwhite::Show white point on CIE diagram, by default disabled.\gamma::Set input gamma. Used only with XYZ input color space.		
ffmpegvfilter	codecview	::Visualize information exported by some codecs. Some codecs can export information through frames using side-data or other means. For example, some MPEG based codecs export motion vectors through the export_mvs flag in the codec flags2 option. Examples 1 Visualize forward predicted MVs of all frames using ffplay: ffplay -flags2 +export_mvs input.mp4 -vf codecview=mv_type=fp 2) Visualize multi-directionals MVs of P and B-Frames using ffplay: ffplay -flags2 +export_mvs input.mp4 -vf codecview=mv=pf+bf+bb\mv::Set motion vectors to visualize. Available flags for mv are: ‘pf’-forward predicted MVs of P-frames ‘bf’-forward predicted MVs of B-frames ‘bb’-backward predicted MVs of B-frames\qp::Display quantization parameters using the chroma planes.\mv_type::Set motion vectors type to visualize. Includes MVs from all frames unless specified by frame_type option. Available flags for mv_type are: ‘fp’-forward predicted MVs ‘bp’-backward predicted MVs\frame_type::Set frame type to visualize motion vectors of. Available flags for frame_type are: ‘if’-intra-coded frames (I-frames) ‘pf’-predicted frames (P-frames) ‘bf’-bi-directionally predicted frames (B-frames)		
ffmpegvfilter	colorbalance	::Modify intensity of primary colors (red, green and blue) of input frames. The filter allows an input frame to be adjusted in the shadows, midtones or highlights regions for the red-cyan, green-magenta or blue-yellow balance. A positive adjustment value shifts the balance towards the primary color, a negative value towards the complementary color. Example Add red color cast to shadows: colorbalance=rs=.3\rs::\gs::\bs::Adjust red, green and blue shadows (darkest pixels).\rm::\gm::\bm::Adjust red, green and blue midtones (medium pixels).\rh:0:\gh:0:\bh:0:Adjust red, green and blue highlights (brightest pixels). Allowed ranges for options are [-1.0, 1.0]. Defaults are 0.		
ffmpegvfilter	colorkey	:: RGB colorspace color keying. Examples 1 Make every green pixel in the input image transparent: ffmpeg -i input.png -vf colorkey=green out.png 2 Overlay a greenscreen-video on top of a static background image. ffmpeg -i background.png -i video.mp4 -filter_complex "[1:v]colorkey=0x3BBD1E:0.3:0.2[ckout];[0:v][ckout]overlay[out]" -map "[out]" output.flv\color::The color which will be replaced with transparency.\similarity::Similarity percentage with the key color. 0.01 matches only the exact key color, while 1.0 matches everything. \blend::Blend percentage. 0.0 makes pixels either fully transparent, or not transparent at all. Higher values result in semi-transparent pixels, with a higher transparency the more similar the pixels color is to the key color.		
ffmpegvfilter	colorlevels	::Adjust video input frames using levels. Examples 1 Make video output darker: colorlevels=rimin=0.058:gimin=0.058:bimin=0.058 2 Increase contrast: colorlevels=rimin=0.039:gimin=0.039:bimin=0.039:rimax=0.96:gimax=0.96:bimax=0.96 3 Make video output lighter: colorlevels=rimax=0.902:gimax=0.902:bimax=0.902 4 Increase brightness: colorlevels=romin=0.5:gomin=0.5:bomin=0.5\rimin:0:Adjust red, green, blue and alpha input black point. Allowed ranges for options are [-1.0, 1.0].\gimin:0:Adjust red, green, blue and alpha input black point. Allowed ranges for options are [-1.0, 1.0].\bimin:0:Adjust red, green, blue and alpha input black point. Allowed ranges for options are [-1.0, 1.0].\aimin:0:Adjust red, green, blue and alpha input black point. Allowed ranges for options are [-1.0, 1.0].\rimax:1:Adjust red, green, blue and alpha input white point. Allowed ranges for options are [-1.0, 1.0].\gimax:1:Adjust red, green, blue and alpha input white point. Allowed ranges for options are [-1.0, 1.0].\bimax:1:Adjust red, green, blue and alpha input white point. Allowed ranges for options are [-1.0, 1.0].\aimax:1:Adjust red, green, blue and alpha input white point. Allowed ranges for options are [-1.0, 1.0].Input levels are used to lighten highlights (bright tones), darken shadows (dark tones), change the balance of bright and dark tones.\romin:0:Adjust red, green, blue and alpha output black point. Allowed ranges for options are [0, 1.0]. \gomin:0:Adjust red, green, blue and alpha output black point. Allowed ranges for options are [0, 1.0]. \bomin:0:Adjust red, green, blue and alpha output black point. Allowed ranges for options are [0, 1.0]. \aomin:0:Adjust red, green, blue and alpha output black point. Allowed ranges for options are [0, 1.0].\romax:1:Adjust red, green, blue and alpha output white point. Allowed ranges for options are [0, 1.0].\gomax:1:Adjust red, green, blue and alpha output white point. Allowed ranges for options are [0, 1.0].\bomax:1:Adjust red, green, blue and alpha output white point. Allowed ranges for options are [0, 1.0].\aomax:1:Adjust red, green, blue and alpha output white point. Allowed ranges for options are [0, 1.0]. Output levels allows manual selection of a constrained output level range.		
ffmpegvfilter	colorchannelmixer	::Adjust video input frames by re-mixing color channels. This filter modifies a color channel by adding the values associated to the other channels of the same pixels. For example if the value to modify is red, the output value will be: red=red*rr + blue*rb + green*rg + alpha*ra\rr:1:Adjust contribution of input red, green, blue and alpha channels for output red channel.Examples 1 Convert source to grayscale: colorchannelmixer=.3:.4:.3:0:.3:.4:.3:0:.3:.4:.3 2 Simulate sepiatones: colorchannelmixer=.393:.769:.189:0:.349:.686:.168:0:.272:.534:.131 \rg:0:Adjust contribution of input red, green, blue and alpha channels for output red channel.\rb:0:Adjust contribution of input red, green, blue and alpha channels for output red channel.\ra:1:Adjust contribution of input red, green, blue and alpha channels for output red channel. Default is 1 for rr, and 0 for rg, rb and ra.\gr:1:Adjust contribution of input red, green, blue and alpha channels for output green channel.\gg:0:Adjust contribution of input red, green, blue and alpha channels for output green channel.\gb:0:Adjust contribution of input red, green, blue and alpha channels for output green channel.\ga:0:Adjust contribution of input red, green, blue and alpha channels for output green channel.\br:1:Adjust contribution of input red, green, blue and alpha channels for output blue channel.\bg:0:Adjust contribution of input red, green, blue and alpha channels for output blue channel. \bg:0:Adjust contribution of input red, green, blue and alpha channels for output blue channel.\bb:0:Adjust contribution of input red, green, blue and alpha channels for output blue channel.\ba:0:Adjust contribution of input red, green, blue and alpha channels for output blue channel.\ar:1:Adjust contribution of input red, green, blue and alpha channels for output alpha channel.\ag:0:Adjust contribution of input red, green, blue and alpha channels for output alpha channel.\ab:0:Adjust contribution of input red, green, blue and alpha channels for output alpha channel.\aa:0:Adjust contribution of input red, green, blue and alpha channels for output alpha channel.		
ffmpegvfilter	colormatrix	::Convert color matrix.\src::Specify the source and destination color matrix. Both values must be specified.\dst:: The accepted values are:‘bt709’ BT.709 ‘fcc’ FCC ‘bt601’ BT.601 ‘bt470’ BT.470 ‘bt470bg’ BT.470BG ‘smpte170m’ SMPTE-170M ‘smpte240m’ SMPTE-240M ‘bt2020’ BT.2020 For example to convert from BT.601 to SMPTE-240M, use the command: colormatrix=bt601:smpte240mcolorspace::Convert colorspace, transfer characteristics or color primaries. Input video needs to have an even size. The filter converts the transfer characteristics, color space and color primaries to the specified user values. The output value, if not specified, is set to a default value based on the "all" property. If that property is also not specified, the filter will log an error. The output color range and format default to the same value as the input color range and format. The input transfer characteristics, color space, color primaries and color range should be set on the input data. If any of these are missing, the filter will log an error and no conversion will take place. For example to convert the input to SMPTE-240M, use the command:colorspace=smpte240m\all:: Specify all color properties at once.The accepted values are: ‘bt470m’ BT.470M ‘bt470bg’ BT.470BG ‘bt601-6-525’ BT.601-6 525 ‘bt601-6-625’ BT.601-6 625 ‘bt709’ BT.709 ‘smpte170m’ SMPTE-170M ‘smpte240m’ SMPTE-240M ‘bt2020’ BT.2020 \space::Specify output colorspace. The accepted values are: ‘bt709’ BT.709 ‘fcc’ FCC ‘bt470bg’ BT.470BG or BT.601-6 625 ‘smpte170m’ SMPTE-170M or BT.601-6 525 ‘smpte240m’ SMPTE-240M ‘ycgco’ YCgCo ‘bt2020ncl’ BT.2020 with non-constant luminance\trc::Specify output transfer characteristics. The accepted values are: ‘bt709’ BT.709 ‘bt470m’ BT.470M ‘bt470bg’ BT.470BG   ‘gamma22’ Constant gamma of 2.2 ‘gamma28’ Constant gamma of 2.8 ‘smpte170m’ SMPTE-170M, BT.601-6 625 or BT.601-6 525 ‘smpte240m’ SMPTE-240M ‘srgb’ SRGB ‘iec61966-2-1’ iec61966-2-1 ‘iec61966-2-4’ iec61966-2-4 ‘xvycc’ xvycc ‘bt2020-10’ BT.2020 for 10-bits content ‘bt2020-12’ BT.2020 for 12-bits content \primaries::Specify output color primaries. The accepted values are: ‘bt709’ BT.709 ‘bt470m’ BT.470M ‘bt470bg’ BT.470BG or BT.601-6 625 ‘smpte170m’ SMPTE-170M or BT.601-6 525 ‘smpte240m’ SMPTE-240M ‘film’ film ‘smpte431’ SMPTE-431 smpte432’ SMPTE-432 ‘bt2020’ BT.2020 ‘jedec-p22’ JEDEC P22 phosphors\range::Specify output color range. The accepted values are: ‘tv’ TV (restricted) range ‘mpeg’ MPEG (restricted) range ‘pc’ PC (full) range ‘jpeg’ JPEG (full) range\format::Specify output color format. The accepted values are: ‘yuv420p’ YUV 4:2:0 planar 8-bits ‘yuv420p10’ YUV 4:2:0 planar 10-bits ‘yuv420p12’ YUV 4:2:0 planar 12-bits ‘yuv422p’ YUV 4:2:2 planar 8-bits ‘yuv422p10’ YUV 4:2:2 planar 10-bits ‘yuv422p12’ YUV 4:2:2 planar 12-bits ‘yuv444p’ YUV 4:4:4 planar 8-bits ‘yuv444p10’ YUV 4:4:4 planar 10-bits ‘yuv444p12’ YUV 4:4:4 planar 12-bits\fast::Do a fast conversion, which skips gamma/primary correction. This will take significantly less CPU, but will be mathematically incorrect. To get output compatible with that produced by the colormatrix filter, use fast=1.\dither::Specify dithering mode.The accepted values are: ‘none’ No dithering ‘fsb’ Floyd-Steinberg dithering\wpadapt::Whitepoint adaptation mode. The accepted values are: ‘bradford’ Bradford whitepoint adaptation ‘vonkries’ von Kries whitepoint  adaptation ‘identity’ identity whitepoint adaptation (i.e. no whitepoint adaptation) iall Override all input properties at once. Same accepted values as all. ispace Override input colorspace. Same accepted values as space.\iprimaries::Override input color primaries. Same accepted values as primaries.\itrc::Override input transfer characteristics. Same accepted values as trc.\irange::Override input color range. Same accepted values as range.		
ffmpegvfilter	convolution	::Apply convolution of 3x3, 5x5, 7x7 or horizontal/vertical up to 49 elements. Parameters: 0m,1m,2m,3m Set matrix for each plane. Matrix is sequence of 9, 25 or 49 signed integers in square mode, and from 1 to 49 odd number of signed integers in row mode. 0rdiv,1rdiv,2rdiv,3rdiv Set multiplier for calculated value for each plane. If unset or 0, it will be sum of all matrix elements. 0bias,1bias,2bias,3bias Set bias for each plane. This value is added to the result of the multiplication. Useful for making the overall image brighter or darker. Default is 0.0. 0mode,1mode,2mode Set matrix mode for each plane. Can be square, row or column.\3mode:square:Set matrix mode for each plane. Can be square, row or column. Defaut is square Examples 1)Apply sharpen: convolution="0 -1 0 -1 5 -1 0 -1 0:0 -1 0 -1 5 -1 0 -1 0:0 -1 0 -1 5 -1 0 -1 0:0 -1 0 -1 5 -1 0 -1 0" 2) Apply blur: convolution="1 1 1 1 1 1 1 1 1:1 1 1 1 1 1 1 1 1:1 1 1 1 1 1 1 1 1:1 1 1 1 1 1 1 1 1:1/9:1/9:1/9:1/9"3) 3)Apply edge enhance: convolution="0 0 0 -1 1 0 0 0 0:0 0 0 -1 1 0 0 0 0:0 0 0 -1 1 0 0 0 0:0 0 0 -1 1 0 0 0 0:5:1:1:1:0:128:128:128"4) Apply edge detect: convolution="0 1 0 1 -4 1 0 1 0:0 1 0 1 -4 1 0 1 0:0 1 0 1 -4 1 0 1 0:0 1 0 1 -4 1 0 1 0:5:5:5:1:0:128:128:128"5) Apply laplacian edge detector which includes diagonals:6)convolution="1 1 1 1 -8 1 1 1 1:1 1 1 1 -8 1 1 1 1:1 1 1 1 -8 1 1 1 1:1 1 1 1 -8 1 1 1 1:5:5:5:1:0:128:128:0"6)Apply emboss: convolution="-2 -1 0 -1 1 1 0 1 2:-2 -1 0 -1 1 1 0 1 2:-2 -1 0 -1 1 1 0 1 2:-2 -1 0 -1 1 1 0 1 2"		
ffmpegvfilter	convolve	::Apply 2D convolution of video stream in frequency domain using second stream as impulse. The convolve filter also supports the framesync options.\planes::Set which planes to process.\impulse:all:Set which impulse video frames will be processed, can be first or all		
ffmpegvfilter	copy	::Copy the input video source unchanged to the output. This is mainly useful for testing purposes.		
ffmpegvfilter	coreimage	::Video filtering on GPU using Apple’s CoreImage API on OSX. Hardware acceleration is based on an OpenGL context. Usually, this means it is processed by video hardware. However, software-based OpenGL implementations exist which means there is no guarantee for hardware processing. It depends on the respective OSX. There are many filters and image generators provided by Apple that come with a large variety of options. The filter has to be referenced by its name along with its options./filter::Specify all filters by their respective name and options. Use list_filters to determine all valid filter names and options. Numerical options are specified by a float value and are automatically clamped to their respective value range. Vector and color options have to be specified by a list of space separated float values. Character escaping has to be done. A special option name default is available to use default options for a filter. It is required to specify either default or at least one of the filter options. All omitted options are used with their default values. The syntax of the filter string is as follows: filter=<NAME>@<OPTION>=<VALUE>[@<OPTION>=<VALUE>][@...][#<NAME>@<OPTION>=<VALUE>[@<OPTION>=<VALUE>][@...]][#...]. Several filters can be chained for successive processing without GPU-HOST transfers allowing for fast processing of complex filter chains. Currently, only filters with zero (generators) or exactly one (filters) input image and one output image are supported. Also, transition filters are not yet usable as intended. Some filters generate output images with additional padding depending on the respective filter kernel. The padding is automatically removed to ensure the filter output has the same size as the input image. For image generators, the size of the output image is determined by the previous output image of the filter chain or the input image of the whole filterchain, respectively. The generators do not use the pixel information of this image to generate their output. However, the generated output is blended onto this image, resulting in partial or complete coverage of the output image. The coreimagesrc video source can be used for generating input images which are directly fed into the filter chain. By using it, providing input images by another video source or an input video is not required. Examples 1) List all filters available: coreimage=list_filters=true 2) Use the CIBoxBlur filter with default options to blur an image: coreimage=filter=CIBoxBlur@default 3) Use a filter chain with CISepiaTone at default values and CIVignetteEffect with its center at 100x100 and a radius of 50 pixels: 4) coreimage::filter=CIBoxBlur@default#CIVignetteEffect@inputCenter=100 Backslash 100@inputRadius=50 \output_rect::Specify a rectangle where the output of the filter chain is copied into the input image. It is given by a list of space separated float values: output_rect=x Backslash y Backslash  width Backslash  height If not given, the output rectangle equals the dimensions of the input image. The output rectangle is automatically cropped at the borders of the input image. Negative values are valid for each component.		
ffmpegvfilter	crop	::Crop the input video to given dimensions.\out_w:: The width of the output video. It defaults to iw. This expression is evaluated only once during the filter configuration, or when the ‘w’ or ‘out_w’ command is sent. The out_w, out_h, x, y parameters are expressions containing the following constants: x,y The computed values for x and y. They are evaluated for each new frame; in_w,in_h The input width and height; iw,ih These are the same as in_w and in_h; out_w, out_h The output (cropped) width and height; ow, oh These are the same as out_w and out_h; a same as iw / ih;sar input Sample aspect ratio; dar input display aspect ratio, it is the same as (iw / ih) * sar; hsub, vsub horizontal and vertical chroma subsample values. For example for the pixel format "yuv422p" hsub is 2 and vsub is 1; n The number of the input frame, starting from 0; pos the position in the file of the input frame, NAN if unknown; t The timestamp expressed in seconds. It’s NAN if the input timestamp is unknown. The expression for out_w may depend on the value of out_h, and the expression for out_h may depend on out_w, but they cannot depend on x and y, as x and y are evaluated after out_w and out_h. The x and y parameters specify the expressions for the position of the top-left corner of the output (non-cropped) area. They are evaluated for each frame. If the evaluated value is not valid, it is approximated to the nearest valid value. The expression for x may depend on y, and the expression for y may depend on x.  Examples 1) Crop area with size 100x100 at position (12,34) crop=100:100:12:34 2) Using named options, the example above becomes: crop=w=100:h=100:x=12:y=34 2a)Crop the central input area with size 100x100: crop=100:100 3) Crop the central input area with size 2/3 of the input video: crop=2/3*in_w:2/3*in_h 4) Crop the input video central square: crop=out_w=in_h crop=in_h 5) Delimit the rectangle with the top-left corner placed at position 100:100 and the right-bottom corner corresponding to the right-bottom corner of the input image. crop=in_w-100:in_h-100:100:100 6) Crop 10 pixels from the left and right borders, and 20 pixels from the top and bottom borders crop=in_w-2*10:in_h-2*20 7) Keep only the bottom right quarter of the input image: crop=in_w/2:in_h/2:in_w/2:in_h/2 8) Crop height for getting Greek harmony: crop=in_w:1/PHI*in_w 9) Apply trembling effect: crop=in_w/2:in_h/2:(in_w-out_w)/2+((in_w-out_w)/2)*sin(n/10):(in_h-out_h)/2 +((in_h-out_h)/2)*sin(n/7) 10) Apply erratic camera effect depending on timestamp:crop=in_w/2:in_h/2:(in_w-out_w)/2+((in_w-out_w)/2)*sin(t*10):(in_h-out_h)/2 +((in_h-out_h)/2)*sin(t*13)" 11) Set x depending on the value of y: crop=in_w/2:in_h/2:y:10+10*sin(n/10) Commands-This filter supports the following commands: w, out_w,h, out_h, x, y, Set width/height of the output video and the horizontal/vertical position in the input video. The command accepts the same syntax of the corresponding option.If the specified expression is not valid, it is kept at its current value. \out_h:: (or w) The height of the output video. It defaults to ih. This expression is evaluated only once during the filter configuration, or when the ‘h’ or ‘out_h’ command is sent.\x::The horizontal position, in the input video, of the left edge of the output video. It defaults to (in_w-out_w)/2. This expression is evaluated per-frame.\y::The vertical position, in the input video, of the top edge of the output video. It defaults to (in_h-out_h)/2. This expression is evaluated per-frame.\keep_aspect:0:If set to 1 will force the output display aspect ratio to be the same of the input, by changing the output sample aspect ratio.\exact:0:Enable exact cropping. If enabled, subsampled videos will be cropped at exact width/height/x/y as specified and will not be rounded to nearest smaller value.		
ffmpegvfilter	cropdetect	::Auto-detect the crop size.It calculates the necessary cropping parameters and prints the recommended parameters via the logging system. The detected dimensions correspond to the non-black area of the input video.\limit::Set higher black value threshold, which can be optionally specified from nothing (0) to everything (255 for 8-bit based formats). An intensity value greater to the set value is considered non-black. It defaults to 24. You can also specify a value between 0.0 and 1.0 which will be scaled depending on the bitdepth of the pixel format.\round::The value which the width/height should be divisible by. It defaults to 16. The offset is automatically adjusted to center the video. Use 2 to get only even dimensions (needed for 4:2:2 video). 16 is best when encoding to most video codecs.\reset_count:0:or Reset Set the counter that determines after how many frames cropdetect will reset the previously detected largest video area and start over to detect the current optimal crop area. This can be useful when channel logos distort the video area. 0 indicates ’never reset’, and returns the largest area encountered during playback.		
ffmpegvfilter	cue	::Delay video filtering until a given wallclock timestamp. The filter first passes on preroll amount of frames, then it buffers at most buffer amount of frames and waits for the cue. After reaching the cue it forwards the buffered frames and also any subsequent frames coming in its input.The filter can be used synchronize the output of multiple ffmpeg processes for realtime output devices like decklink. By putting the delay in the filtering chain and pre-buffering frames the process can pass on data to output almost immediately after the target wallclock timestamp is reached. Perfect frame accuracy cannot be guaranteed, but the result is good enough for some use cases.\cue:0:The cue timestamp expressed in a UNIX timestamp in microseconds. \preroll:0:The duration of content to pass on as preroll expressed in seconds.\buffer:0:The maximum duration of content to buffer before waiting for the cue expressed in seconds.		
ffmpegvfilter	curves	::Apply color adjustments using curves. This filter is similar to the Adobe Photoshop and GIMP curves tools. Each component (red, green and blue) has its values defined by N key points tied from each other using a smooth curve. The x-axis represents the pixel values from the input frame, and the y-axis the new pixel values to be set for the output frame. By default, a component curve is defined by the two points (0;0) and (1;1). This creates a straight line where each original pixel value is "adjusted" to its own value, which means no change to the image. The filter allows you to redefine these two points and add some more. A new curve (using a natural cubic spline interpolation) will be define to pass smoothly through all these new coordinates. The new defined points needs to be strictly increasing over the x-axis, and their x and y values must be in the [0;1] interval. If the computed curves happened to go outside the vector spaces, the values will be clipped accordingly. Examples 1) Increase slightly the middle level of blue: curves=blue='0/0 0.5/0.58 1/1' 2) Vintage effect: curves=r='0/0.11 .42/.51 1/0.95':g='0/0 0.50/0.48 1/1':b='0/0.22 .49/.44 1/0.8' Here we obtain the following coordinates for each components: red(0;0.11) (0.42;0.51) (1;0.95) green (0;0) (0.50;0.48) (1;1) blue (0;0.22) (0.49;0.44) (1;0.80) The previous example can also be achieved with the associated built-in preset: curves=preset=vintage Or simply: curves=vintage 3) Use a Photoshop preset and redefine the points of the green component: curves=psfile='MyCurvesPresets/purple.acv':green='0/0 0.45/0.53 1/1' 4) Check out the curves of the cross_process profile using ffmpeg and gnuplot:ffmpeg -f lavfi -i color -vf curves=cross_process:plot=/tmp/curves.plt -frames:v 1 -f null - gnuplot -p /tmp/curves.plt\preset:: Select one of the available color presets. This option can be used in addition to the r, g, b parameters; in this case, the later options takes priority on the preset values. Available presets are:‘none’ ‘color_negative’ ‘cross_process’ ‘darker’ ‘increase_contrast’ ‘lighter’ ‘linear_contrast’ ‘medium_contrast’ ‘negative’ ‘strong_contrast’ ‘vintage’ Default is none.\master:: Also m Set the master key points. These points will define a second pass mapping. It is sometimes called a "luminance" or "value" mapping. It can be used with r, g, b or all since it acts like a post-processing LUT.\red::Also r Set the key points for the red component.\green::Also g Set the key points for the green component.\blue::Also b Set the key points for the blue component.\all::Set the key points for all components (not including master). Can be used in addition to the other key points component options. In this case, the unset component(s) will fallback on this all setting.\psfile::Specify a Photoshop curves file (.acv) to import the settings from.\plot::Save Gnuplot script of the curves in specified file. To avoid some filtergraph syntax conflicts, each key points list need to be defined using the following syntax: x0/y0 x1/y1 x2/y2 ....		
ffmpegvfilter	datascope	::Video data analysis filter. This filter shows hexadecimal pixel values of part of video.\size::Set output video size.\x::Set x offset from where to pick pixels.\y::Set y offset from where to pick pixels.\mode::Set scope mode, can be one of the following:‘mono’-Draw hexadecimal pixel values with white color on black background. ‘color’-Draw hexadecimal pixel values with input video pixel color on black background. ‘color2’-Draw hexadecimal pixel values on color background picked from input video, the text color is picked in such way so its always visible.\axis::Draw rows and columns numbers on left and top of video.\opacity::Set background opacity.\1thr:0.02:Set banding detection threshold for each plane.  Valid range is 0.00003 to 0.5. If difference between current pixel and reference pixel is less than threshold, it will be considered as banded.\2thr:0.02:Set banding detection threshold for each plane.  Valid range is 0.00003 to 0.5. If difference between current pixel and reference pixel is less than threshold, it will be considered as banded.\3thr:0.02:Set banding detection threshold for each plane.  Valid range is 0.00003 to 0.5. If difference between current pixel and reference pixel is less than threshold, it will be considered as banded.\4thr:0.02:Set banding detection threshold for each plane.  Valid range is 0.00003 to 0.5. If difference between current pixel and reference pixel is less than threshold, it will be considered as banded.\range:16:Banding detection range in pixels. Default is 16. If positive, random number in range 0 to set value will be used. If negative, exact absolute value will be used. The range defines square of four pixels around current pixel.\direction::Set direction in radians from which four pixel will be compared. If positive, random direction from 0 to set direction will be picked. If negative, exact of absolute value will be picked. For example direction 0, -PI or -2*PI radians will pick only pixels on same row and -PI/2 will pick only pixels on same column.\blur::If enabled, current pixel is compared with average value of all four surrounding pixels. The default is enabled. If disabled current pixel is compared with all four surrounding pixels. The pixel is considered banded if only all four differences with surrounding pixels are less than threshold.\coupling::If enabled, current pixel is changed if and only if all pixel components are banded, e.g. banding detection threshold is triggered for all color components. The default is disabled.		
ffmpegvfilter	deblock::Remove blocking artifacts from input video. Examples: 1)Deblock using weak filter and block size of 4 pixels. deblock=filter=weak:block=4, 2) Deblock using strong filter, block size of 4 pixels and custom thresholds for deblocking more edges. deblock=filter=strong:block=4:alpha=0.12:beta=0.07:gamma=0.06:delta=0.05 3) Similar as above, but filter only first plane.deblock=filter=strong:block=4:alpha=0.12:beta=0.07:gamma=0.06:delta=0.05:planes=1, 4) Similar as above, but filter only second and third plane. deblock=filter=strong:block=4:alpha=0.12:beta=0.07:gamma=0.06:delta=0.05:planes=6\filter:strong:Set filter type, can be weak or strong.This controls what kind of deblocking is applied.\block:8:Set size of block, allowed range is from 4 to 512.\alpha:0.098:Set blocking detection thresholds. Allowed range is 0 to 1.Using higher threshold gives more deblocking strength. Setting alpha controls threshold detection at exact edge of block. Remaining options controls threshold detection near the edge. Each one for below/above or left/right. Setting any of those to 0 disables deblocking.\beta:0.05:Set blocking detection thresholds. Allowed range is 0 to 1.Using higher threshold gives more deblocking strength. Setting alpha controls threshold detection at exact edge of block. Remaining options controls threshold detection near the edge. Each one for below/above or left/right. Setting any of those to 0 disables deblocking.\gamma:0.05:Set blocking detection thresholds. Allowed range is 0 to 1.Using higher threshold gives more deblocking strength. Setting alpha controls threshold detection at exact edge of block. Remaining options controls threshold detection near the edge. Each one for below/above or left/right. Setting any of those to 0 disables deblocking.\delta:0.05:Set blocking detection thresholds. Allowed range is 0 to 1.Using higher threshold gives more deblocking strength. Setting alpha controls threshold detection at exact edge of block. Remaining options controls threshold detection near the edge. Each one for below/above or left/right. Setting any of those to 0 disables deblocking.\planes::Set planes to filter. Default is to filter all available planes.			
ffmpegvfilter	decimate	::Drop duplicated frames at regular intervals.\cycle:5:Set the number of frames from which one will be dropped. Setting this to N means one frame in every batch of N frames will be dropped.\dupthresh:1.1:Set the threshold for duplicate detection. If the difference metric for a frame is less than or equal to this value, then it is declared as duplicate.\scthresh:15:Set scene change threshold.\blockx:32:Set the size of the x-axis block used during metric calculations. Larger blocks give better noise suppression, but also give worse detection of small movements. Must be a power of two.\blocky:32:Set the size of the y-axis block used during metric calculations. Larger blocks give better noise suppression, but also give worse detection of small movements. Must be a power of two.\ppsrc:0:Mark main input as a pre-processed input and activate clean source input stream. This allows the input to be pre-processed with various filters to help the metrics calculation while keeping the frame selection lossless. When set to 1, the first stream is for the pre-processed input, and the second stream is the clean source from where the kept frames are chosen.\chroma:1:Set whether or not chroma is considered in the metric calculations.		
ffmpegvfilter	deconvolve	::Apply 2D deconvolution of video stream in frequency domain using second stream as impulse. The deconvolve filter also supports the framesync options.\planes::Set which planes to process.\impulse:all:Set which impulse video frames will be processed, can be first or all. Default is all.\noise:0.0000001:Set noise when doing divisions.Useful when width and height are not same and not power of 2 or if stream prior to convolving had noise.		
ffmpegvfilter	dedot	::Reduce cross-luminance (dot-crawl) and cross-color (rainbows) from video.\m::Set mode of operation. Can be combination of dotcrawl for cross-luminance reduction and/or rainbows for cross-color reduction.\lt::Set spatial luma threshold. Lower values increases reduction of cross-luminance.\tl::Set tolerance for temporal luma. Higher values increases reduction of cross-luminance.\tc::Set tolerance for chroma temporal variation. Higher values increases reduction of cross-color.\ct::Set temporal chroma threshold. Lower values increases reduction of cross-color.		
ffmpegvfilter	deflate	::Apply deflate effect to the video. This filter replaces the pixel by the local(3x3) average by taking into account only values lower than the pixel.\threshold0:65535:Limit the maximum change for each plane. If 0, plane will remain unchanged.\threshold1:65535:Limit the maximum change for each plane. If 0, plane will remain unchanged.\threshold2:65535:Limit the maximum change for each plane. If 0, plane will remain unchanged.\threshold3:65535:Limit the maximum change for each plane. If 0, plane will remain unchanged.		
ffmpegvfilter	deflicker	::Remove temporal frame luminance variations.\size:5:Set moving-average filter size in frames. Allowed range is 2 - 129.\mode::Set averaging mode to smooth temporal luminance variations. Available values are: ‘am’ Arithmetic mean, ‘gm’ Geometric mean, ‘hm’ Harmonic mean, ‘qm’ Quadratic mean, ‘cm’ Cubic mean, ‘pm’ Power mean, ‘median’ Median\bypass::Do not actually modify frame. Useful when one only wants metadata.		
ffmpegvfilter	dejudder	::Remove judder produced by partially interlaced telecined content. Judder can be introduced, for instance, by pullup filter. If the original source was partially telecined content then the output of pullup,dejudder will have a variable frame rate. May change the recorded frame rate of the container. Aside from that change, this filter will not affect constant frame rate video.\cycle:4:Specify the length of the window over which the judder repeats. Accepts any integer greater than 1. Useful values are: ‘4’ If the original was telecined from 24 to 30 fps (Film to NTSC), ‘5’ If the original was telecined from 25 to 30 fps (PAL to NTSC), ‘20’ If a mixture of the two.		
ffmpegvfilter	deshake	::Attempt to fix small changes in horizontal and/or vertical shift. This filter helps remove camera shake from hand-holding a camera, bumping a tripod, moving on a vehicle, etc.\x::Specify a rectangular area where to limit the search for motion vectors. If desired the search for motion vectors can be limited to a rectangular area of the frame defined by its top left corner, width and height. These parameters have the same meaning as the drawbox filter which can be used to visualise the position of the bounding box. This is useful when simultaneous movement of subjects within the frame might be confused for camera motion by the motion vector search. If any or all of x, y, w and h are set to -1 then the full frame is used. This allows later options to be set without specifying the bounding box for the motion vector search.\y::Specify a rectangular area where to limit the search for motion vectors. If desired the search for motion vectors can be limited to a rectangular area of the frame defined by its top left corner, width and height. These parameters have the same meaning as the drawbox filter which can be used to visualise the position of the bounding box. This is useful when simultaneous movement of subjects within the frame might be confused for camera motion by the motion vector search. If any or all of x, y, w and h are set to -1 then the full frame is used. This allows later options to be set without specifying the bounding box for the motion vector search.\w::Specify a rectangular area where to limit the search for motion vectors. If desired the search for motion vectors can be limited to a rectangular area of the frame defined by its top left corner, width and height. These parameters have the same meaning as the drawbox filter which can be used to visualise the position of the bounding box. This is useful when simultaneous movement of subjects within the frame might be confused for camera motion by the motion vector search. If any or all of x, y, w and h are set to -1 then the full frame is used. This allows later options to be set without specifying the bounding box for the motion vector search.\h::Specify a rectangular area where to limit the search for motion vectors. If desired the search for motion vectors can be limited to a rectangular area of the frame defined by its top left corner, width and height. These parameters have the same meaning as the drawbox filter which can be used to visualise the position of the bounding box. This is useful when simultaneous movement of subjects within the frame might be confused for camera motion by the motion vector search. If any or all of x, y, w and h are set to -1 then the full frame is used. This allows later options to be set without specifying the bounding box for the motion vector search.\rx:16:Specify the maximum extent of movement in x direction in the range 0-64 pixels.\ry:16:Specify the maximum extent of movement in x and y directions in the range 0-64 pixels.\edge:mirrow:Specify how to generate pixels to fill blanks at the edge of the frame. Available values are: ‘blank, 0’ Fill zeroes at blank locations' ‘original, 1’ Original image at blank locations; ‘clamp, 2’ Extruded edge value at blank locations' ‘mirror, 3’ Mirrored edge at blank locations\blocksize:8:Specify the blocksize to use for motion search. Range 4-128 pixels.\contrast:125:Specify the contrast threshold for blocks. Only blocks with more than the specified contrast (difference between darkest and lightest pixels) will be considered. Range 1-255.\search:exhaustive: Specify the search strategy. Available values are: ‘exhaustive, 0’ Set exhaustive search; ‘less, 1’ Set less exhaustive search./filename:: If set then a detailed log of the motion search is written to the specified file.		
ffmpegvfilter	despill	::Remove unwanted contamination of foreground colors, caused by reflected color of greenscreen or bluescreen.\type::Set what type of despill to use.\mix::Set how spillmap will be generated.\expand::Set how much to get rid of still remaining spill.\red::Controls amount of red in spill area.\green::Controls amount of green in spill area. Should be -1 for greenscreen.\blue::Controls amount of blue in spill area. Should be -1 for bluescreen.\brightness::Controls brightness of spill area, reserving colors.\alpha::Modify alpha from generated spillmap.		
ffmpegvfilter	drawbox	::Draw a colored box on the input image. The parameters for x, y, w and h and t are expressions containing the following constants: 1)dar-The input display aspect ratio, it is the same as (w / h) * sar. 2) hsub,vsub-horizontal and vertical chroma subsample values. For example for the pixel format "yuv422p" hsub is 2 and vsub is 1. 3) in_h, ih,in_w, iw-The input width and height. 4) sar-The input sample aspect ratio. 5)x,y-The x and y offset coordinates where the box is drawn. 6)w,h-The width and height of the drawn box.6) t-The thickness of the drawn box. These constants allow the x, y, w, h and t expressions to refer to each other, so you may for example specify y=x/dar or h=w/dar. Examples: 1) Draw a black box around the edge of the input image: drawbox 2) Draw a box with color red and an opacity of 50%: drawbox=10:20:200:60:red@0.5 3)The previous example can be specified as: drawbox=x=10:y=20:w=200:h=60:color=red@0.5 4) Fill the box with pink color: drawbox=x=10:y=10:w=100:h=100:color=pink@0.5:t=fill 5) Draw a 2-pixel red 2.40:1 mask: drawbox=x=-t:y=0.5*(ih-iw/2.4)-t:w=iw+t*2:h=iw/2.4+t*2:t=2:c=red\x:0:The expressions which specify the left corner coordinates of the box. \y:0:The expressions which specify the top left corner coordinates of the box.\width:0:The expression which specify the width of the box; if 0 they are interpreted as the input width and height.\height:0:The expression which specify the height of the box; if 0 they are interpreted as the input width and height.\color::Specify the color of the box to write. For the general syntax of this option, check the (ffmpeg-utils)"Color" section in the ffmpeg-utils manual. If the special value invert is used, the box edge color is the same as the video with inverted luma.\thickness:3:The expression which sets the thickness of the box edge. A value of fill will create a filled box.\replace:0:Applicable if the input has alpha. With value 1, the pixels of the painted box will overwrite the video’s color and alpha pixels. Default is 0, which composites the box onto the input, leaving the video’s alpha intact.		
ffmpegvfilter	drawgrid	::Draw a grid on the input image. Examples: 1) Draw a grid with cell 100x100 pixels, thickness 2 pixels, with color red and an opacity of 50%: drawgrid=width=100:height=100:thickness=2:color=red@0.5 2) Draw a white 3x3 grid with an opacity of 50%: drawgrid=w=iw/3:h=ih/3:t=2:c=white@0.5 It accepts the following parameters: The list of accepted constants for parameters. 1) replace-Applicable if the input has alpha. With 1 the pixels of the painted grid will overwrite the video’s color and alpha pixels. Default is 0, which composites the grid onto the input, leaving the video’s alpha intact. The parameters for x, y, w and h and t are expressions containing the following constants: 1) dar-The input display aspect ratio, it is the same as (w / h) * sar. 2) hsub, vsub-horizontal and vertical chroma subsample values. For example for the pixel format "yuv422p" hsub is 2 and vsub is 1. 3) in_h, ih, in_w, iw-The input grid cell width and height. 3) sar-The input sample aspect ratio. 4)x,y-The x and y coordinates of some point of grid intersection (meant to configure offset). 5)w.h-The width and height of the drawn cell. 6)t-The thickness of the drawn cell. These constants allow the x, y, w, h and t expressions to refer to each other, so you may for example specify y=x/dar or h=w/dar.\x:0:The expressions which specify the coordinates of some point of grid intersection (meant to configure offset).\y:0:The expressions which specify the coordinates of some point of grid intersection (meant to configure offset).\width:0:specify the widthof the grid cell, if 0 they are interpreted as the input width, respectively, minus thickness, so image gets framed.\height:0: specify the height of the grid cell, if 0 they are interpreted as the input height, respectively, minus thickness, so image gets framed.\color::Specify the color of the grid. For the general syntax of this option, check the (ffmpeg-utils)"Color" section in the ffmpeg-utils manual. If the special value invert is used, the grid color is the same as the video with inverted luma.\thickness:1:The expression which sets the thickness of the grid line.		
ffmpegvfilter	drawtext	::Draw a text string or text from a specified file on top of a video, using the libfreetype library. To enable compilation of this filter, you need to configure FFmpeg with --enable-libfreetype. To enable default font fallback and the font option you need to configure FFmpeg with --enable-libfontconfig. To enable the text_shaping option, you need to configure FFmpeg with --enable-libfribidi. Examples: 1) Draw "Test Text" with font FreeSerif, using the default values for the optional parameters. drawtext="fontfile=/usr/share/fonts/truetype/freefont/FreeSerif.ttf: text='Test Text'" 2) Draw ’Test Text’ with font FreeSerif of size 24 at position x=100 and y=50 (counting from the top-left corner of the screen), text is yellow with a red box around it. Both the text and the box have an opacity of 20%. drawtext="fontfile=/usr/share/fonts/truetype/freefont/FreeSerif.ttf: text='Test Text':  x=100: y=50: fontsize=24: fontcolor=yellow@0.2: box=1: boxcolor=red@0.2" Note that the double quotes are not necessary if spaces are not used within the parameter list.  3) Show a text line sliding from right to left in the last row of the video frame. The file LONG_LINE is assumed to contain a single line with no newlines.: drawtext="fontsize=15:fontfile=FreeSerif.ttf:text=LONG_LINE:y=h-line_h:x=-50*t" 4) Show the content of file CREDITS off the bottom of the frame and scroll up.: drawtext="fontsize=20:fontfile=FreeSerif.ttf:textfile=CREDITS:y=h-20*t" 5) Draw a single green letter "g", at the center of the input video. The glyph baseline is placed at half screen height: drawtext="fontsize=60:fontfile=FreeSerif.ttf:fontcolor=green:text=g:x=(w-max_glyph_w)/2:y=h/2-ascent" The parameters for x, y, w and h and t are expressions containing the following constants: 1) dar-The input display aspect ratio, it is the same as (w / h) * sar. 2) hsub, vsub-horizontal and vertical chroma subsample values. For example for the pixel format "yuv422p" hsub is 2 and vsub is 1. 3) in_h, ih, in_w, iw-The input grid cell width and height. 3) sar-The input sample aspect ratio. 4)x,y-The x and y coordinates of some point of grid intersection (meant to configure offset). 5)w.h-The width and height of the drawn cell. 6)t-The thickness of the drawn cell. These constants allow the x, y, w, h and t expressions to refer to each other, so you may for example specify y=x/dar or h=w/dar.\boxborderw:0: Set the width of the border to be drawn around the box using boxcolor.\boxcolor:white:The color to be used for drawing box around text. For the syntax of this option, check the (ffmpeg-utils)"Color" section in the ffmpeg-utils manual.\line_spacing:0:Set the line spacing in pixels of the border to be drawn around the box using box.\borderw:0:Set the width of the border to be drawn around the text using bordercolor.\bordercolor:black:Set the color to be used for drawing border around text. For the syntax of this option, check the (ffmpeg-utils)"Color" section in the ffmpeg-utils manual.\expansion::Select how the text is expanded. Can be either none, strftime (deprecated) or normal (default). See the Text expansion section for details.\basetime::Set a start time for the count. Value is in microseconds. Only applied in the deprecated strftime expansion mode. To emulate in normal expansion mode use the pts function, supplying the start time (in seconds) as the second argument.\fix_bounds::If true, check and fix text coords to avoid clipping.\fontcolor:black:The color to be used for drawing fonts. For the syntax of this option, check the (ffmpeg-utils)"Color" section in the ffmpeg-utils manual.\fontcolor_expr::String which is expanded the same way as text to obtain dynamic fontcolor value. By default this option has empty value and is not processed. When this option is set, it overrides fontcolor option.\font:Sans:The font family to be used for drawing text.\fontfile::The font file to be used for drawing text. The path must be included. This parameter is mandatory if the fontconfig support is disabled.\alpha:1:Draw the text applying alpha blending. The value can be a number between 0.0 and 1.0. The expression accepts the same variables x, y as well. Please see fontcolor_expr.\fontsize:16:The font size to be used for drawing text.\text_shaping:1:If set to 1, attempt to shape the text (for example, reverse the order of right-to-left text and join Arabic characters) before drawing it. Otherwise, just draw the text exactly as given.\ft_load_flags:default:The flags to be used for loading the fonts. The flags map the corresponding flags supported by libfreetype, and are a combination of the following values: default,no_scale,no_hinting,render,no_bitmap,vertical_layout,force_autohint,crop_bitmap,pedantic,ignore_global_advance_width,no_recurse,ignore_transform,monochrome,linear_design,no_autohint. For more information consult the documentation for the FT_LOAD_* libfreetype flags.\shadowcolor:black:The color to be used for drawing a shadow behind the drawn text. For the syntax of this option, check the (ffmpeg-utils)"Color" section in the ffmpeg-utils manual.\shadowx:0:The x offset for the text shadow position with respect to the position of the text. They can be either positive or negative values.\shadowy:0:The  y offset for the text shadow position with respect to the position of the text. They can be either positive or negative values.\start_number:0:The starting frame number for the n/frame_num variable.\tabsize:4:The size in number of spaces to use for rendering the tab.\timecode::Set the initial timecode representation in "hh:mm:ss[:;.]ff" format. It can be used with or without text parameter. timecode_rate option must be specified.\timecode_rate::Set the timecode frame rate (timecode only). Value will be rounded to nearest integer. Minimum value is "1". Drop-frame timecode is supported for frame rates 30 & 60.\tc24hmax:0:If set to 1, the output of the timecode option will wrap around at 24 hours. Ddefault is 0 (disabled).\text::The text string to be drawn. The text must be a sequence of UTF-8 encoded characters. This parameter is mandatory if no file is specified with the parameter textfile.\textfile::A text file containing text to be drawn. The text must be a sequence of UTF-8 encoded characters. This parameter is mandatory if no text string is specified with the parameter text. If both text and textfile are specified, an error is thrown.\reload:: If set to 1, the textfile will be reloaded before each frame. Be sure to update it atomically, or it may be read partially, or even fail.\x:0:\y:0:The expressions which specify the offsets where text will be drawn within the video frame. They are relative to the top/left border of the output image.		
ffmpegafilter	alphaextract	::Extract the alpha component from the input as a grayscale video. This is especially useful with the alphamerge filter.		
ffmpegafilter	Amplify	:2:Amplify differences between current pixel and pixels of adjacent frames in same pixel location.\radius:2:Set frame radius. Allowed range is from 1 to 63. For example radius of 3 will instruct filter to calculate average of 7 frames.\factor:2:Set factor to amplify difference.  Allowed range is from 0 to 65535.\threshold:10:Set threshold for difference amplification. Any differrence greater or equal to this value will not alter source pixel.  Allowed range is from 0 to 65535.\low::Set lower limit for changing source pixel. Allowed range is from 0 to 65535. This option controls maximum possible value that will decrease source pixel value.\high:65535:Set high limit for changing source pixel.  Allowed range is from 0 to 65535. This option controls maximum possible value that will increase source pixel value.\planes::Set which planes to filter. Default is all. Allowed range is from 0 to 15.		
ffmpegafilter	ass	:auto:Same as the subtitles filter, except that it doesn�t require libavcodec and libavformat to work. On the other hand, it is limited to ASS (Advanced Substation Alpha) subtitles files.\shaping:auto:Set the shaping engine,Available values are:�auto� The default libass shaping engine, which is the best available. �simple� Fast, font-agnostic shaper that can do only substitutions �complex� Slower shaper using OpenType for substitutions and positioning. The default is auto.		
ffmpegafilter	atadenoise	::Apply an Adaptive Temporal Averaging Denoiser to the video input.\0a:0.02:Set threshold A for 1st plane. Default is 0.02. Valid range is 0 to 0.3.\0b:0.04:Set threshold B for 1st plane. Default is 0.04. Valid range is 0 to 5.\1a:0.02:Set threshold A for 2nd plane. Default is 0.02. Valid range is 0 to 0.3.\1b:0.04:Set threshold B for 2nd plane. Default is 0.04. Valid range is 0 to 5.\2a:0.02:Set threshold A for 3rd plane. Default is 0.02. Valid range is 0 to 0.3.\2b:0.04:Set threshold B for 3rd plane. Default is 0.04. Valid range is 0 to 5. Threshold A is designed to react on abrupt changes in the input signal and threshold B is designed to react on continuous changes in the input signal.\s:9:Set number of frames filter will use for averaging. Default is 9. Must be odd number in range [5, 129].\p::Set what planes of frame filter will use for averaging. Default is all.		
ffmpegafilter	avgblur	::Apply average blur filter.\sizeX::Set horizontal radius size.\sizeY:0:Set vertical radius size, if zero it will be same as sizeX.\planes::Set which planes to filter. By default all planes are filtered.		
ffmpegafilter	bbox	::Compute the bounding box for the non-black pixels in the input frame luminance plane.This filter computes the bounding box containing all the pixels with a luminance value greater than the minimum allowed value. The parameters describing the bounding box are printed on the filter log.\min_val:16:Set the minimal luminance value.\bitplanenoise::Show and measure bit plane noise.\bitplane:1:Set which plane to analyze.\filter::Filter out noisy pixels from bitplane set above. Default is disabled.		
ffmpegafilter	blackdetect	::Detect video intervals that are (almost) completely black. Can be useful to detect chapter transitions, commercials, or invalid recordings. Output lines contains the time for the start, end and duration of the detected black interval expressed in seconds.In order to display the output lines, you need to set the loglevel at least to the AV_LOG_INFO value.\black_min_duration:2.0:Set the minimum detected black duration expressed in seconds. It must be a non-negative floating point number.\picture_black_ratio_th, pic_th:0.98:Set the threshold for considering a picture "black". Express the minimum value for the ratio: nb_black_pixels / nb_pixels for which a picture is considered black.\pixel_black_th:0.10:Set the threshold for considering a pixel "black". The threshold expresses the maximum pixel luminance value for hich a pixel is considered "black". The provided value is scaled according to the following equation: absolute_threshold = luminance_minimum_value + pixel_black_th * luminance_range_size. luminance_range_size and luminance_minimum_value depend on the input video format, the range is [0-255] for YUV full-range formats and [16-235] for YUV non full-range formats. The following example sets the maximum pixel threshold to the minimum value, and detects only black intervals of 2 or more seconds  blackdetect=d=2:pix_th=0.00		
ffmpegafilter	blackframe	::Detect frames that are (almost) completely black. Can be useful to detect chapter transitions or commercials. Output lines consist of the frame number of the detected frame, the percentage of blackness, the position in the file if known or -1 and the timestamp in seconds. In order to display the output lines, you need to set the loglevel at least to the AV_LOG_INFO value. This filter exports frame metadata lavfi.blackframe.pblack. The value represents the percentage of pixels in the picture that are below the threshold value.\amount:98:The percentage of the pixels that have to be below the threshold.\threshold:32:The threshold below which a pixel value is considered black.		
ffmpegafilter	blend	::Blend two video frames into each other. The blend filter takes two input streams and outputs one stream, the first input is the "top" layer and second input is "bottom" layer. By default, the output terminates when the longest input terminates. The tblend (time blend) filter takes two consecutive frames from one single stream, and outputs the result obtained by blending the new frame on top of the old frame. Available values for component modes are: �addition�,�grainmerge�,�and�,�average�,�burn�,�darken�,�difference�,�grainextract�,�divide�,�dodge�,�freeze�,�exclusion�,�extremity�,�glow�,�hardlight�,�hardmix�,�heat�,�lighten�,�li,earlight�,�multiply�,�multiply128�,�negation�,�normal�,�or�,�overlay�,�phoenix�,�pinlight��reflect�,�screen�,�softlight�,�subtract�,�vividlight�,�xor�,,c0_opacityc1_opacity,c2_opacity,c3_opacity,all_opacity. Set blend opacity for specific pixel component or all pixel components in case of all_opacity. Only used in combination with pixel component blend modes. c0_expr,c1_expr,c2_expr,c3_expr,all_expr. Set blend expression for specific pixel component or all pixel components in case of all_expr. Note that related mode options will be ignored if those are set.The blend filter also supports the framesync options. Examples 1)Apply transition from bottom layer to top layer in first 10 seconds: blend=all_expr='A*(if(gte(T,10),1,T/10))+B*(1-(if(gte(T,10),1,T/10)))' 2) Apply linear horizontal transition from top layer to bottom layer:blend=all_expr='A*(X/W)+B*(1-X/W)' 3: Apply 1x1 checkerboard effect:blend=all_expr='if(eq(mod(X,2),mod(Y,2)),A,B)' 4) Apply uncover left effect: blend=all_expr='if(gte(N*SW+X,W),A,B)' 5) Apply uncover down effect: blend=all_expr='if(gte(Y-N*SH,0),A,B)' 6) Apply uncover up-left effect: blend=all_expr='if(gte(T*SH*40+Y,H)*gte((T*40*SW+X)*W/H,W),A,B)' 7) Split diagonally video and shows top and bottom layer on each side: blend=all_expr='if(gt(X,Y*(W/H)),A,B)' 8) Display differences between the current and the previous frame: blend=all_mode=grainextract\c0_mode::\ c1_mode::\c2_mode::\c3_mode::\all_mode::Default value is normal.\N::The sequential number of the filtered frame, starting from 0.\X::x  coordinate of the current sample\Y::y  coordinate of the current sample\W::width of currently filtered plane\H::height of currently filtered plane\SW::Width scale for the plane being filtered. It is the ratio between the dimensions of the current plane to the luma plane, e.g. for a yuv420p frame, the values are 1 for the luma plane and 0.5  for the chroma planes.\SH::Height scale for the plane being filtered. It is the ratio between the dimensions of the current plane to the luma plane, e.g. for a yuv420p frame, the values are 1 for the luma plane and 0.5for the chroma planes.\T::Time of the current frame, expressed in seconds.\TOP::Value of pixel component at current location for first video frame (top layer).\BOTTOM::Value of pixel component at current location for second video frame (bottom layer).		